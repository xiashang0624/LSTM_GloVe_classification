{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os, csv\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix, csc_matrix, diags\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xia_Dell\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Input, LSTM, Embedding, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "#from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Accepted_answer_prediction_data_train.txt', sep ='\\t',\n",
    "                 header=None,names=['C_ID','Description','U_ID','Type','Time'])\n",
    "label = pd.read_csv('Accepted_answer_prediction_labels_train.txt', sep ='\\t',\n",
    "                 header=None,names=['C_ID','label'])\n",
    "df = pd.merge(df, label, on=['C_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_file='Sample/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['length'] = [len(str(des).split()) for des in df['Description'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle data and train/test split\n",
    "df = shuffle(df)\n",
    "train_frac = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_D = 100 # Dimension of the embedding.  Here we chose 100\n",
    "doc_len = 300 # we chose certain number of words used in the model. For documents with fewer words, zero padding will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>U_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>11946</td>\n",
       "      <td>christian christian group local church recover...</td>\n",
       "      <td>93</td>\n",
       "      <td>A</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>18291</td>\n",
       "      <td>view follow christ christian continu fulfil ju...</td>\n",
       "      <td>491</td>\n",
       "      <td>A</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>14417</td>\n",
       "      <td>church period preach long time fanci oratori a...</td>\n",
       "      <td>233</td>\n",
       "      <td>A</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>11374</td>\n",
       "      <td>trend capit word bibl koran extrem simpl reaso...</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9831</th>\n",
       "      <td>21673</td>\n",
       "      <td>question make sens mention triniti understand ...</td>\n",
       "      <td>713</td>\n",
       "      <td>A</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C_ID                                        Description  U_ID Type  \\\n",
       "2536  11946  christian christian group local church recover...    93    A   \n",
       "7295  18291  view follow christ christian continu fulfil ju...   491    A   \n",
       "4389  14417  church period preach long time fanci oratori a...   233    A   \n",
       "2107  11374  trend capit word bibl koran extrem simpl reaso...    72    A   \n",
       "9831  21673  question make sens mention triniti understand ...   713    A   \n",
       "\n",
       "      Time  label  length  \n",
       "2536  0.02      0     236  \n",
       "7295  0.28      0      69  \n",
       "4389  0.19      1     138  \n",
       "2107  0.94      0      68  \n",
       "9831  0.42      0      78  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Prepare X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15464, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Doc = df[\"Description\"].fillna(\"NA\").values\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(Train_Doc))\n",
    "Train_tokenize = tokenizer.texts_to_sequences(Train_Doc)\n",
    "X_t = pad_sequences(Train_tokenize, maxlen=doc_len)\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "Since the given dataset has been preprocess. we will apply stemming on the embedding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xia_Dell\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {}\n",
    "f = open(embedding_file, encoding=\"utf8\")\n",
    "for word_vec in f:\n",
    "    word_vec = word_vec.split()\n",
    "    word = word_vec[0]\n",
    "    vec = np.asarray(word_vec[1:])\n",
    "    embedding[p.stem(word)] = vec.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the embedding volcabulary after stemming treatment is  332346\n"
     ]
    }
   ],
   "source": [
    "print ('the length of the embedding volcabulary after stemming treatment is ', len(embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the embedding matrix with random numbers based on the mean and std of the embedding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb_values = np.stack(embedding.values())\n",
    "emb_mean = emb_values.mean()\n",
    "emb_std = emb_values.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index\n",
    "vocab_len = len(vocab)+1 # here the reason of adding 1 is because the index of word in vocab starts at 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_Matrix = np.random.normal(emb_mean, emb_std, (vocab_len, emb_D))\n",
    "for w, i in vocab.items():\n",
    "    embed_Vector = embedding.get(w)\n",
    "    if embed_Vector is not None: \n",
    "        embed_Matrix[i] = embed_Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Input(shape=(doc_len,))\n",
    "b = Embedding(vocab_len, emb_D, weights=[embed_Matrix])(a)\n",
    "b = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(b)\n",
    "b = GlobalMaxPool1D()(b)\n",
    "b = Dense(100, activation=\"elu\")(b)\n",
    "b = Dropout(0.2)(b)\n",
    "b = Dense(50, activation=\"elu\")(b)\n",
    "b = Dropout(0.2)(b)\n",
    "# b = Dense(20, activation=\"elu\")(b)\n",
    "# b = Dropout(0.15)(b)\n",
    "b = Dense(1, activation=\"sigmoid\")(b)\n",
    "model = Model(inputs=a, outputs=b)\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=[sensitivity, specificity, 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12371 samples, validate on 3093 samples\n",
      "Epoch 1/50\n",
      "12371/12371 [==============================] - 339s 27ms/step - loss: 0.6239 - sensitivity: 0.6581 - specificity: 0.6502 - acc: 0.6501 - val_loss: 0.7892 - val_sensitivity: 0.1811 - val_specificity: 0.8983 - val_acc: 0.7459\n",
      "Epoch 2/50\n",
      "12371/12371 [==============================] - 324s 26ms/step - loss: 0.5587 - sensitivity: 0.7008 - specificity: 0.7113 - acc: 0.7085 - val_loss: 0.7681 - val_sensitivity: 0.6098 - val_specificity: 0.5513 - val_acc: 0.5613\n",
      "Epoch 3/50\n",
      "12371/12371 [==============================] - 285s 23ms/step - loss: 0.4696 - sensitivity: 0.7793 - specificity: 0.7661 - acc: 0.7687 - val_loss: 0.9921 - val_sensitivity: 0.3010 - val_specificity: 0.7765 - val_acc: 0.6760\n",
      "Epoch 4/50\n",
      "12371/12371 [==============================] - 337s 27ms/step - loss: 0.3598 - sensitivity: 0.8643 - specificity: 0.8283 - acc: 0.8340 - val_loss: 1.3246 - val_sensitivity: 0.2143 - val_specificity: 0.8252 - val_acc: 0.6977\n",
      "Epoch 5/50\n",
      "12371/12371 [==============================] - 363s 29ms/step - loss: 0.2698 - sensitivity: 0.9044 - specificity: 0.8779 - acc: 0.8824 - val_loss: 1.7363 - val_sensitivity: 0.2209 - val_specificity: 0.8203 - val_acc: 0.6951\n",
      "Epoch 6/50\n",
      "12371/12371 [==============================] - 218s 18ms/step - loss: 0.2016 - sensitivity: 0.9334 - specificity: 0.9086 - acc: 0.9133 - val_loss: 2.0834 - val_sensitivity: 0.2089 - val_specificity: 0.8341 - val_acc: 0.7032\n",
      "Epoch 7/50\n",
      "12371/12371 [==============================] - 215s 17ms/step - loss: 0.1411 - sensitivity: 0.9461 - specificity: 0.9410 - acc: 0.9427 - val_loss: 1.9792 - val_sensitivity: 0.2951 - val_specificity: 0.7691 - val_acc: 0.6683\n",
      "Epoch 8/50\n",
      "12371/12371 [==============================] - 216s 17ms/step - loss: 0.1114 - sensitivity: 0.9551 - specificity: 0.9522 - acc: 0.9539 - val_loss: 2.8593 - val_sensitivity: 0.1646 - val_specificity: 0.8611 - val_acc: 0.7155\n",
      "Epoch 9/50\n",
      "12371/12371 [==============================] - 199s 16ms/step - loss: 0.0883 - sensitivity: 0.9656 - specificity: 0.9620 - acc: 0.9631 - val_loss: 2.8642 - val_sensitivity: 0.2011 - val_specificity: 0.8350 - val_acc: 0.7016\n",
      "Epoch 10/50\n",
      "12371/12371 [==============================] - 197s 16ms/step - loss: 0.0749 - sensitivity: 0.9754 - specificity: 0.9688 - acc: 0.9703 - val_loss: 2.8237 - val_sensitivity: 0.2256 - val_specificity: 0.7903 - val_acc: 0.6718\n",
      "Epoch 11/50\n",
      "12371/12371 [==============================] - 196s 16ms/step - loss: 0.0584 - sensitivity: 0.9782 - specificity: 0.9761 - acc: 0.9766 - val_loss: 3.4827 - val_sensitivity: 0.2170 - val_specificity: 0.7992 - val_acc: 0.6770\n",
      "Epoch 12/50\n",
      "12371/12371 [==============================] - 195s 16ms/step - loss: 0.0652 - sensitivity: 0.9773 - specificity: 0.9725 - acc: 0.9735 - val_loss: 3.3542 - val_sensitivity: 0.2375 - val_specificity: 0.7909 - val_acc: 0.6744\n",
      "Epoch 13/50\n",
      "12371/12371 [==============================] - 195s 16ms/step - loss: 0.0481 - sensitivity: 0.9839 - specificity: 0.9830 - acc: 0.9836 - val_loss: 4.5829 - val_sensitivity: 0.1018 - val_specificity: 0.9195 - val_acc: 0.7478\n",
      "Epoch 14/50\n",
      "12371/12371 [==============================] - 195s 16ms/step - loss: 0.0481 - sensitivity: 0.9834 - specificity: 0.9808 - acc: 0.9816 - val_loss: 3.8189 - val_sensitivity: 0.1593 - val_specificity: 0.8665 - val_acc: 0.7177\n",
      "Epoch 15/50\n",
      "12371/12371 [==============================] - 195s 16ms/step - loss: 0.0398 - sensitivity: 0.9851 - specificity: 0.9846 - acc: 0.9854 - val_loss: 3.4309 - val_sensitivity: 0.2762 - val_specificity: 0.7719 - val_acc: 0.6680\n",
      "Epoch 16/50\n",
      "12371/12371 [==============================] - 195s 16ms/step - loss: 0.0402 - sensitivity: 0.9858 - specificity: 0.9830 - acc: 0.9837 - val_loss: 3.5442 - val_sensitivity: 0.2579 - val_specificity: 0.7811 - val_acc: 0.6705\n",
      "Epoch 17/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0419 - sensitivity: 0.9850 - specificity: 0.9829 - acc: 0.9836 - val_loss: 3.8501 - val_sensitivity: 0.1790 - val_specificity: 0.8479 - val_acc: 0.7064\n",
      "Epoch 18/50\n",
      "12371/12371 [==============================] - 195s 16ms/step - loss: 0.0354 - sensitivity: 0.9863 - specificity: 0.9859 - acc: 0.9861 - val_loss: 4.1863 - val_sensitivity: 0.1793 - val_specificity: 0.8348 - val_acc: 0.6967\n",
      "Epoch 19/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0277 - sensitivity: 0.9895 - specificity: 0.9881 - acc: 0.9885 - val_loss: 4.5234 - val_sensitivity: 0.1928 - val_specificity: 0.8392 - val_acc: 0.7026\n",
      "Epoch 20/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0349 - sensitivity: 0.9856 - specificity: 0.9874 - acc: 0.9876 - val_loss: 4.6477 - val_sensitivity: 0.1393 - val_specificity: 0.8871 - val_acc: 0.7291\n",
      "Epoch 21/50\n",
      "12371/12371 [==============================] - 195s 16ms/step - loss: 0.0334 - sensitivity: 0.9892 - specificity: 0.9864 - acc: 0.9871 - val_loss: 4.5001 - val_sensitivity: 0.1755 - val_specificity: 0.8555 - val_acc: 0.7123\n",
      "Epoch 22/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0281 - sensitivity: 0.9861 - specificity: 0.9904 - acc: 0.9905 - val_loss: 4.4461 - val_sensitivity: 0.1528 - val_specificity: 0.8606 - val_acc: 0.7119\n",
      "Epoch 23/50\n",
      "12371/12371 [==============================] - 193s 16ms/step - loss: 0.0296 - sensitivity: 0.9921 - specificity: 0.9890 - acc: 0.9895 - val_loss: 4.1732 - val_sensitivity: 0.2180 - val_specificity: 0.8192 - val_acc: 0.6929\n",
      "Epoch 24/50\n",
      "12371/12371 [==============================] - 193s 16ms/step - loss: 0.0316 - sensitivity: 0.9906 - specificity: 0.9885 - acc: 0.9888 - val_loss: 4.3230 - val_sensitivity: 0.1551 - val_specificity: 0.8699 - val_acc: 0.7187\n",
      "Epoch 25/50\n",
      "12371/12371 [==============================] - 193s 16ms/step - loss: 0.0286 - sensitivity: 0.9888 - specificity: 0.9889 - acc: 0.9895 - val_loss: 4.5646 - val_sensitivity: 0.1430 - val_specificity: 0.8918 - val_acc: 0.7333\n",
      "Epoch 26/50\n",
      "12371/12371 [==============================] - 193s 16ms/step - loss: 0.0224 - sensitivity: 0.9929 - specificity: 0.9915 - acc: 0.9915 - val_loss: 4.6217 - val_sensitivity: 0.1931 - val_specificity: 0.8396 - val_acc: 0.7029\n",
      "Epoch 27/50\n",
      "12371/12371 [==============================] - 193s 16ms/step - loss: 0.0210 - sensitivity: 0.9934 - specificity: 0.9932 - acc: 0.9936 - val_loss: 4.7531 - val_sensitivity: 0.1438 - val_specificity: 0.8704 - val_acc: 0.7165\n",
      "Epoch 28/50\n",
      "12371/12371 [==============================] - 193s 16ms/step - loss: 0.0272 - sensitivity: 0.9928 - specificity: 0.9897 - acc: 0.9901 - val_loss: 3.9529 - val_sensitivity: 0.2239 - val_specificity: 0.8087 - val_acc: 0.6838\n",
      "Epoch 29/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0223 - sensitivity: 0.9930 - specificity: 0.9916 - acc: 0.9919 - val_loss: 4.3813 - val_sensitivity: 0.1969 - val_specificity: 0.8328 - val_acc: 0.6980\n",
      "Epoch 30/50\n",
      "12371/12371 [==============================] - 197s 16ms/step - loss: 0.0206 - sensitivity: 0.9912 - specificity: 0.9921 - acc: 0.9922 - val_loss: 4.5382 - val_sensitivity: 0.1564 - val_specificity: 0.8694 - val_acc: 0.7181\n",
      "Epoch 31/50\n",
      "12371/12371 [==============================] - 200s 16ms/step - loss: 0.0182 - sensitivity: 0.9930 - specificity: 0.9931 - acc: 0.9935 - val_loss: 4.6552 - val_sensitivity: 0.1953 - val_specificity: 0.8132 - val_acc: 0.6822\n",
      "Epoch 32/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0160 - sensitivity: 0.9933 - specificity: 0.9946 - acc: 0.9949 - val_loss: 4.0407 - val_sensitivity: 0.2954 - val_specificity: 0.7360 - val_acc: 0.6434\n",
      "Epoch 33/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0193 - sensitivity: 0.9885 - specificity: 0.9934 - acc: 0.9935 - val_loss: 4.9035 - val_sensitivity: 0.2047 - val_specificity: 0.8405 - val_acc: 0.7051\n",
      "Epoch 34/50\n",
      "12371/12371 [==============================] - 194s 16ms/step - loss: 0.0222 - sensitivity: 0.9937 - specificity: 0.9930 - acc: 0.9929 - val_loss: 3.9197 - val_sensitivity: 0.1958 - val_specificity: 0.8263 - val_acc: 0.6941\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12371/12371 [==============================] - 191s 15ms/step - loss: 0.0238 - sensitivity: 0.9837 - specificity: 0.9901 - acc: 0.9905 - val_loss: 4.5227 - val_sensitivity: 0.2068 - val_specificity: 0.8222 - val_acc: 0.6925\n",
      "Epoch 36/50\n",
      "12371/12371 [==============================] - 188s 15ms/step - loss: 0.0196 - sensitivity: 0.9931 - specificity: 0.9927 - acc: 0.9930 - val_loss: 5.2660 - val_sensitivity: 0.1526 - val_specificity: 0.8812 - val_acc: 0.7262\n",
      "Epoch 37/50\n",
      "12371/12371 [==============================] - 185s 15ms/step - loss: 0.0110 - sensitivity: 0.9929 - specificity: 0.9962 - acc: 0.9964 - val_loss: 4.4053 - val_sensitivity: 0.2442 - val_specificity: 0.7619 - val_acc: 0.6537\n",
      "Epoch 38/50\n",
      "12371/12371 [==============================] - 182s 15ms/step - loss: 0.0180 - sensitivity: 0.9927 - specificity: 0.9945 - acc: 0.9945 - val_loss: 4.2194 - val_sensitivity: 0.2631 - val_specificity: 0.7490 - val_acc: 0.6469\n",
      "Epoch 39/50\n",
      "12371/12371 [==============================] - 181s 15ms/step - loss: 0.0189 - sensitivity: 0.9927 - specificity: 0.9934 - acc: 0.9934 - val_loss: 4.4359 - val_sensitivity: 0.1719 - val_specificity: 0.8488 - val_acc: 0.7055\n",
      "Epoch 40/50\n",
      "12371/12371 [==============================] - 179s 14ms/step - loss: 0.0128 - sensitivity: 0.9970 - specificity: 0.9954 - acc: 0.9958 - val_loss: 4.1514 - val_sensitivity: 0.2815 - val_specificity: 0.7625 - val_acc: 0.6612\n",
      "Epoch 41/50\n",
      "12371/12371 [==============================] - 177s 14ms/step - loss: 0.0187 - sensitivity: 0.9935 - specificity: 0.9930 - acc: 0.9930 - val_loss: 4.3084 - val_sensitivity: 0.2142 - val_specificity: 0.8174 - val_acc: 0.6893\n",
      "Epoch 42/50\n",
      "12371/12371 [==============================] - 174s 14ms/step - loss: 0.0141 - sensitivity: 0.9915 - specificity: 0.9943 - acc: 0.9946 - val_loss: 5.0481 - val_sensitivity: 0.1702 - val_specificity: 0.8735 - val_acc: 0.7239\n",
      "Epoch 43/50\n",
      "12371/12371 [==============================] - 173s 14ms/step - loss: 0.0161 - sensitivity: 0.9947 - specificity: 0.9940 - acc: 0.9939 - val_loss: 5.1801 - val_sensitivity: 0.1707 - val_specificity: 0.8679 - val_acc: 0.7197\n",
      "Epoch 44/50\n",
      "12371/12371 [==============================] - 171s 14ms/step - loss: 0.0144 - sensitivity: 0.9959 - specificity: 0.9950 - acc: 0.9951 - val_loss: 4.7439 - val_sensitivity: 0.1802 - val_specificity: 0.8426 - val_acc: 0.7022\n",
      "Epoch 45/50\n",
      "12371/12371 [==============================] - 172s 14ms/step - loss: 0.0203 - sensitivity: 0.9921 - specificity: 0.9922 - acc: 0.9923 - val_loss: 4.5354 - val_sensitivity: 0.1351 - val_specificity: 0.8888 - val_acc: 0.7284\n",
      "Epoch 46/50\n",
      "12371/12371 [==============================] - 169s 14ms/step - loss: 0.0141 - sensitivity: 0.9897 - specificity: 0.9954 - acc: 0.9951 - val_loss: 5.5931 - val_sensitivity: 0.1306 - val_specificity: 0.8882 - val_acc: 0.7281\n",
      "Epoch 47/50\n",
      "12371/12371 [==============================] - 167s 14ms/step - loss: 0.0120 - sensitivity: 0.9967 - specificity: 0.9957 - acc: 0.9958 - val_loss: 5.6145 - val_sensitivity: 0.1424 - val_specificity: 0.8932 - val_acc: 0.7329\n",
      "Epoch 48/50\n",
      "12371/12371 [==============================] - 166s 13ms/step - loss: 0.0090 - sensitivity: 0.9981 - specificity: 0.9971 - acc: 0.9973 - val_loss: 5.5924 - val_sensitivity: 0.1392 - val_specificity: 0.8997 - val_acc: 0.7375\n",
      "Epoch 49/50\n",
      "12371/12371 [==============================] - 165s 13ms/step - loss: 0.0133 - sensitivity: 0.9937 - specificity: 0.9946 - acc: 0.9950 - val_loss: 5.5144 - val_sensitivity: 0.1612 - val_specificity: 0.8781 - val_acc: 0.7252\n",
      "Epoch 50/50\n",
      "12371/12371 [==============================] - 167s 14ms/step - loss: 0.0148 - sensitivity: 0.9936 - specificity: 0.9953 - acc: 0.9953 - val_loss: 4.9259 - val_sensitivity: 0.2117 - val_specificity: 0.8280 - val_acc: 0.6974\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=32, epochs=50, validation_split=0.2,class_weight={0:class_weights[0],1:class_weights[1]});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*50/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
